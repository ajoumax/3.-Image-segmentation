{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c474212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "#from my_classes import DataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fbd323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "partition = # IDs\n",
    "labels = # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b0aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Load entire dataset\n",
    "X, y = np.load('some_training_set_with_label.npy')\n",
    "\n",
    "# Design model\n",
    "model = Sequential()\n",
    "[...] # Your architecture\n",
    "model.compile()\n",
    "\n",
    "# Train model on your dataset\n",
    "model.fit(x=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c5ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID는 파이썬 문자열로 주어진 데이터셋을 정의함\n",
    "\n",
    "partion 디렉토리를 만듦\n",
    "\n",
    "partition['train']은 트레이닝 ID 리스트\n",
    "partition['validation']은 validation ID 리스트\n",
    "labels 디렉토리를 만들어 각 ID 데이터셋에 상응하는 labels[ID]를 지님\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7155a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "예를 들어 id-1, id-2, id-3은 training이고 id-4는 validation이면 구성은 아래와 같음\n",
    "\n",
    ">>> partition\n",
    "{'train': ['id-1', 'id-2', 'id-3'], 'validation': ['id-4']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf1c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "거기에 상응하는 labels는 아래와 같음\n",
    "\n",
    ">>> labels\n",
    "{'id-1': 0, 'id-2': 1, 'id-3': 2, 'id-4': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1541d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "모듈화를 위해 케라스 코드와 커스터마이즈한 클래스를 분리된 파일과 디렉토리로 아래와 같이 구성해보자.\n",
    "data 디렉토리는 데이터셋을 저장하는 용도\n",
    "\n",
    "\n",
    "folder/\n",
    "├── my_classes.py\n",
    "├── keras_script.py\n",
    "└── data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b76ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798f404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataGenerator.init()\n",
    "이제 파이썬 클래스 DataGenerator에 대해 알아보고 Kera 모델에서 어떻게 실시간 데이터 피딩을 하는지 알아보자.\n",
    "\n",
    "우선, 클래스의 Initialization부터 알아보자.\n",
    "\n",
    "이것을 나중에 keras.utils.Sequence를 상속한 후 사용할 예정이다.\n",
    "위 클래스를 활용하면 멀티 프로세싱을 손쉽게 이용할 수 있다.\n",
    "\n",
    "추가적인 정보인 dim, n_channel, n_classes, shuffle등을 지정하였음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b9ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "             n_classes=10, shuffle=True):\n",
    "    'Initialization'\n",
    "    self.dim = dim\n",
    "    self.batch_size = batch_size\n",
    "    self.labels = labels\n",
    "    self.list_IDs = list_IDs\n",
    "    self.n_channels = n_channels\n",
    "    self.n_classes = n_classes\n",
    "    self.shuffle = shuffle\n",
    "    self.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a5558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e441e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataGenerator.on_epoch_end()\n",
    "on_epoch_end 메소드는 각 epoch의 맨처음과 맨 끝에 실행됨\n",
    "shuffle 파라미터가 True이면 각 epoch마다 새로운 order를 만들어냄\n",
    "필자주) 코드를 보면 단순 index를 shuffle하는 것임\n",
    "shuffle을 통해 각 batch마다 identical한 데이터셋을 학습시키는 것을 방지하여 모델을 좀더 robust하게 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ec945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(self):\n",
    "  'Updates indexes after each epoch'\n",
    "  self.indexes = np.arange(len(self.list_IDs))\n",
    "  if self.shuffle == True:\n",
    "      np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789fce5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataGenerator.__data_generation()\n",
    "__data_generation는 generation process에서 core한 역할인 데이터의 batch를 생성함\n",
    "data generation동안에 이 코드는 ID.npy에 상응하는 example를 NumPy 배열로 만들어냄\n",
    "코드가 multicore friendly 하기 때문에 차후에 더 복잡한 연산도 가능하다.(예: source 파일로 부터 계산)\n",
    "keras.utils.to_categorical 함수를 통해 y에 저장되어 있는 숫자 label을 binary form(예: 6 클래스면 [0 0 1 0 0 0]) 으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e5b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def __data_generation(self, list_IDs_temp):\n",
    "  'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "  # Initialization\n",
    "  X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "  y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "  # Generate data\n",
    "  for i, ID in enumerate(list_IDs_temp):\n",
    "      # Store sample\n",
    "      X[i,] = np.load('data/' + ID + '.npy')\n",
    "\n",
    "      # Store class\n",
    "      y[i] = self.labels[ID]\n",
    "\n",
    "  return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa41fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdb3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataGenerator.len()\n",
    "각 call request는 배치 index 0 ~ 총 batch 크기 만큼 될 수 있다.\n",
    "이부분이 __len__을 통해 컨트롤 된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d170153",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def __len__(self):\n",
    "  'Denotes the number of batches per epoch'\n",
    "  return int(np.floor(len(self.list_IDs) / self.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed0b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "통상적인 total batch size는 아래와 같이 정의됨\n",
    "#sample size / batch size\n",
    "이를 통해 모델이 트레이닝 데이터를 epoch 한번에 거진 한번을 다 보는 효과를 만들어 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93198e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataGenerator.getitem()\n",
    "batch 프로세싱이 주어진 index에 따라 호출 될 때 generator는 __getitem__을 호출함\n",
    "결국 batch size만큼의 entry를 계산해서 리턴해줌\n",
    "예를 들어 batch size가 2이고 index가 10이라면 아래 코드에 의해 indexes에 10, 11이 리턴되고 이에 상응하는 list_IDs[10], list_IDs[11]이 list_IDs_temp에 리턴됨\n",
    "이를 통해 __data_generation(list_IDs_temp)를 통해 알맞은 X, y가 구해짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078efdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def __getitem__(self, index):\n",
    "  'Generate one batch of data'\n",
    "  # Generate indexes of the batch\n",
    "  indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "  # Find list of IDs\n",
    "  list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "  # Generate data\n",
    "  X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b27a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be55c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80243457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                 n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = np.load('data/' + ID + '.npy')\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c8ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b624768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Keras Script\n",
    "이제 위의 DataGenerator를 통해 기존 Keras 코드를 수정해보자.\n",
    "model.fit() 대신에 model.fit_generator()를 호출하였는데 n_workers에 따라 batch가 병렬로 실행 가능하다.\n",
    "충분히 많은 worker는 CPU 연산을 효율적으로 관리함\n",
    "이를 통해 적어도 병목이 CPU가 아니라 feed forward/back prop 과정에서의 GPU가 되게끔 만든다.\n",
    "(필자주: 적어도 CPU 책임은 아니게 만든다는 뜻)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c25360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from my_classes import DataGenerator\n",
    "\n",
    "# Parameters\n",
    "params = {'dim': (32,32,32),\n",
    "          'batch_size': 64,\n",
    "          'n_classes': 6,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Datasets\n",
    "partition = # IDs\n",
    "labels = # Labels\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)\n",
    "\n",
    "# Design model\n",
    "model = Sequential()\n",
    "[...] # Architecture\n",
    "model.compile()\n",
    "\n",
    "# Train model on dataset\n",
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saynot",
   "language": "python",
   "name": "saynot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
